"""Prediction API endpoints.

Supports two backends:
    1. **Advanced AI Models** -- preferred when a trained model exists.
    2. **Machine Learning ensemble** -- fallback via ``src.facade``.
"""

import logging
import sys
import warnings
from pathlib import Path

import numpy as np
from flask import Blueprint, request, jsonify, g

# Suppress feature name warnings
warnings.filterwarnings('ignore', message='X does not have valid feature names')

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.facade import get_model_manager
from webapp.models.prediction_result import save_prediction

logger = logging.getLogger(__name__)

predict_bp = Blueprint('predict', __name__)

_model_manager = None
_dl_predictor = None


def get_manager():
    """Get or initialize the sklearn model manager (legacy fallback)."""
    global _model_manager
    if _model_manager is None:
        _model_manager = get_model_manager()
    return _model_manager


def get_dl_predictor():
    """Get or initialize the DL predictor. Returns None if unavailable."""
    global _dl_predictor
    if _dl_predictor is not None:
        return _dl_predictor

    try:
        from dl_models.inference import DLPredictor
        if DLPredictor.is_available():
            _dl_predictor = DLPredictor()
            _dl_predictor.load()
            logger.info("DL predictor loaded successfully.")
            return _dl_predictor
        logger.info("Advanced AI model not found; will use machine learning fallback.")
    except Exception as e:
        logger.warning("Could not load DL predictor: %s", e)

    return None


@predict_bp.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint."""
    try:
        manager = get_manager()
        loaded_models = manager.get_loaded_modalities()
        
        resp = {
            'status': 'healthy',
            'models_loaded': loaded_models,
            'model_info': manager.get_model_info(),
        }

        dl = get_dl_predictor()
        if dl is not None:
            model_info = dl.get_model_info()
            # Rename to remove DL references for user-facing API
            if 'model_type' in model_info:
                model_info['model_type'] = 'advanced_ai'
            resp['ai_model'] = model_info
            resp['active_backend'] = 'advanced_ai'
        else:
            resp['active_backend'] = 'machine_learning'

        return jsonify(resp)
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500


@predict_bp.route('/predict', methods=['POST'])
def predict():
    """Make a prediction using advanced AI models or machine learning fallback.

    Expected JSON::

        {
            "speech_features": [22 float values] (optional),
            "handwriting_features": [10 float values] (optional),
            "gait_features": [10 float values] (optional)
        }

    At least one modality must be provided.
    """
    try:
        manager = get_manager()
        
        data = request.get_json()
        
        if not data:
            return jsonify({
                'error': 'No data provided',
                'success': False
            }), 400
        
        speech_features = None
        handwriting_features = None
        gait_features = None
        
        # Validate and extract speech features
        if 'speech_features' in data and data['speech_features']:
            speech = data['speech_features']
            if len(speech) != 22:
                return jsonify({
                    'error': f'Expected 22 speech features, got {len(speech)}',
                    'success': False
                }), 400
            speech_features = np.array(speech)
            logger.info("Speech features provided: %d", len(speech))
        
        # Validate and extract handwriting features
        if 'handwriting_features' in data and data['handwriting_features']:
            handwriting = data['handwriting_features']
            if len(handwriting) != 10:
                return jsonify({
                    'error': f'Expected 10 handwriting features, got {len(handwriting)}',
                    'success': False
                }), 400
            handwriting_features = np.array(handwriting)
            logger.info("Handwriting features provided: %d", len(handwriting))
        
        # Validate and extract gait features
        if 'gait_features' in data and data['gait_features']:
            gait = data['gait_features']
            if len(gait) != 10:
                return jsonify({
                    'error': f'Expected 10 gait features, got {len(gait)}',
                    'success': False
                }), 400
            gait_features = np.array(gait)
            logger.info("Gait features provided: %d", len(gait))
        
        # Check if at least one modality is provided
        if speech_features is None and handwriting_features is None and gait_features is None:
            return jsonify({
                'error': 'At least one modality (speech, handwriting, or gait) must be provided',
                'success': False
            }), 400
        
        # Determine which modalities were used
        modalities_used = []
        if speech_features is not None:
            modalities_used.append("speech")
        if handwriting_features is not None:
            modalities_used.append("handwriting")
        if gait_features is not None:
            modalities_used.append("gait")

        # ---- Try Advanced AI predictor first ---- #
        dl = get_dl_predictor()
        if dl is not None:
            logger.info("Using advanced AI predictor")
            result = dl.predict(
                speech_features=speech_features,
                handwriting_features=handwriting_features,
                gait_features=gait_features,
            )
            logger.info(
                "Advanced AI prediction: %s (%.2f%% confidence), attention=%s",
                result['prediction_label'],
                result['confidence'] * 100,
                result.get('attention_weights'),
            )
            
            # Save prediction to database if user is authenticated
            try:
                if hasattr(g, 'current_user') and g.current_user:
                    # Normalize prediction_label format
                    prediction_label = result.get('prediction_label', 'Unknown')
                    if prediction_label.lower() == 'parkinsons':
                        prediction_label = "Parkinson's Disease"
                    elif prediction_label.lower() == 'healthy':
                        prediction_label = "Healthy"
                    
                    # Normalize probabilities keys
                    probabilities = result.get('probabilities', {})
                    normalized_probs = {}
                    for key, value in probabilities.items():
                        if key.lower() == 'parkinsons':
                            normalized_probs["Parkinson's Disease"] = value
                        elif key.lower() == 'healthy':
                            normalized_probs["Healthy"] = value
                        else:
                            normalized_probs[key] = value
                    
                    save_prediction(
                        user_id=str(g.current_user['_id']),
                        result_data={
                            'prediction': result.get('prediction', 0),
                            'prediction_label': prediction_label,
                            'confidence': result.get('confidence', 0.0),
                            'probabilities': normalized_probs,
                            'modalities_used': result.get('modalities_used', modalities_used),
                            'model_type': 'advanced_ai'
                        }
                    )
            except Exception as e:
                logger.warning("Failed to save prediction to database: %s", e)
                # Don't fail the prediction if save fails
            
            return jsonify(result)

        # ---- Fallback: Machine Learning ensemble ---- #
        logger.info("Using machine learning ensemble fallback")
        
        result = manager.predict_ensemble(
            speech_features=speech_features,
            handwriting_features=handwriting_features,
            gait_features=gait_features,
            voting_method='soft',
        )
        
        logger.info(
            "Machine learning prediction: %s (%.2f%% confidence)",
            result['prediction_label'],
            result['confidence'] * 100,
        )
        
        # Save prediction to database if user is authenticated
        try:
            if hasattr(g, 'current_user') and g.current_user:
                # Normalize probabilities keys (sklearn uses lowercase)
                probabilities = result.get('probabilities', {})
                normalized_probs = {}
                for key, value in probabilities.items():
                    if key.lower() == 'parkinsons':
                        normalized_probs["Parkinson's Disease"] = value
                    elif key.lower() == 'healthy':
                        normalized_probs["Healthy"] = value
                    else:
                        normalized_probs[key] = value
                
                save_prediction(
                    user_id=str(g.current_user['_id']),
                    result_data={
                        'prediction': result.get('prediction', 0),
                        'prediction_label': result.get('prediction_label', 'Unknown'),
                        'confidence': result.get('confidence', 0.0),
                        'probabilities': normalized_probs,
                        'modalities_used': result.get('modalities_used', modalities_used),
                        'model_type': 'machine_learning'
                    }
                )
        except Exception as e:
            logger.warning("Failed to save prediction to database: %s", e)
            # Don't fail the prediction if save fails
        
        return jsonify(result)
    
    except Exception as e:
        logger.exception("Prediction failed")
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


@predict_bp.route('/predict_batch', methods=['POST'])
def predict_batch():
    """Make batch predictions.

    Expected JSON::

        {
            "samples": [
                {"speech_features": [...], "handwriting_features": [...], "gait_features": [...]},
                ...
            ]
        }
    """
    try:
        manager = get_manager()
        data = request.get_json()
        
        if not data or 'samples' not in data:
            return jsonify({
                'error': 'No samples provided',
                'success': False
            }), 400
        
        results = []
        for i, sample in enumerate(data['samples']):
            try:
                result = manager.predict_ensemble(
                    speech_features=sample.get('speech_features'),
                    handwriting_features=sample.get('handwriting_features'),
                    gait_features=sample.get('gait_features'),
                    voting_method='soft'
                )
                result['sample_id'] = i
                results.append(result)
            except Exception as e:
                results.append({
                    'sample_id': i,
                    'success': False,
                    'error': str(e)
                })
        
        return jsonify({
            'success': True,
            'results': results,
            'total_samples': len(results)
        })
    
    except Exception as e:
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


@predict_bp.route('/model_info', methods=['GET'])
def model_info():
    """Get information about all loaded models."""
    try:
        manager = get_manager()
        info = manager.get_model_info()
        
        resp = {
            'success': True,
            'models': info['model_details'],
            'loaded_modalities': info['loaded_models'],
        }

        dl = get_dl_predictor()
        if dl is not None:
            model_info = dl.get_model_info()
            # Rename to remove DL references for user-facing API
            if 'model_type' in model_info:
                model_info['model_type'] = 'advanced_ai'
            resp['ai_model'] = model_info
            resp['active_backend'] = 'advanced_ai'
        else:
            resp['active_backend'] = 'machine_learning'

        return jsonify(resp)
    
    except Exception as e:
        return jsonify({
            'error': str(e),
            'success': False
        }), 500
